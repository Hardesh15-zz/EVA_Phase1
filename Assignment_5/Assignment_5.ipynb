{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fifth Assignment",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKaOzFC9r2F7",
        "colab_type": "text"
      },
      "source": [
        "### case1: Activation fuction ReLU after BN - Observation: Validation accuracy(99.48%) has almost no impact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "outputId": "4834f1d3-a9ce-4573-9588-64f590c7c8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "9898c55a-32d1-4717-acef-acf6ade54169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0442241a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATpak7d3KrjP",
        "colab_type": "code",
        "outputId": "28e80ba3-378f-4cff-c39d-07ebe67d9390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print('Number of images in X_train', X_train.shape[0])\n",
        "print('Number of images in X_test', X_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n",
            "Number of images in X_train 60000\n",
            "Number of images in X_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "272d8660-578b-42e1-d506-f2eb4d28554a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "f1a7fb52-413f-4207-ff1f-571e10e1aa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1690
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.regularizers import l2\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01), input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, kernel_regularizer=l2(0.01),)) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1,kernel_regularizer=l2(0.01))) #22\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=l2(0.01)))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4,kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), kernel_regularizer=<keras.reg...)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4), kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR8dgJqv9Skg",
        "colab_type": "code",
        "outputId": "acbc117d-1541-4467-87ae-2820a3b5d0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1653
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create generator that centers pixel values\n",
        "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_datagen = ImageDataGenerator()\n",
        "train_set= train_datagen.flow(X_train, Y_train, batch_size=64)\n",
        "test_set= train_datagen.flow(X_test, Y_test, batch_size=64)\n",
        "\n",
        "model.fit_generator(train_set, \n",
        "                         steps_per_epoch=60000//64, \n",
        "                         validation_data= test_set, \n",
        "                         validation_steps=10000//64, \n",
        "                         epochs=40)\n",
        "\n",
        "                                 \n",
        "                   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:699: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:707: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "937/937 [==============================] - 16s 17ms/step - loss: 0.8178 - acc: 0.8446 - val_loss: 0.3555 - val_acc: 0.9627\n",
            "Epoch 2/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5531 - acc: 0.8642 - val_loss: 0.6174 - val_acc: 0.8677\n",
            "Epoch 3/40\n",
            "937/937 [==============================] - 14s 15ms/step - loss: 0.5490 - acc: 0.8671 - val_loss: 0.3577 - val_acc: 0.9550\n",
            "Epoch 4/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5455 - acc: 0.8679 - val_loss: 0.7860 - val_acc: 0.8235\n",
            "Epoch 5/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5501 - acc: 0.8678 - val_loss: 0.2534 - val_acc: 0.9815\n",
            "Epoch 6/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5344 - acc: 0.8698 - val_loss: 0.2464 - val_acc: 0.9774\n",
            "Epoch 7/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5390 - acc: 0.8692 - val_loss: 0.3766 - val_acc: 0.9390\n",
            "Epoch 8/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5277 - acc: 0.8703 - val_loss: 0.3128 - val_acc: 0.9587\n",
            "Epoch 9/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5279 - acc: 0.8704 - val_loss: 0.4230 - val_acc: 0.9261\n",
            "Epoch 10/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5266 - acc: 0.8704 - val_loss: 0.3089 - val_acc: 0.9552\n",
            "Epoch 11/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5230 - acc: 0.8710 - val_loss: 0.4616 - val_acc: 0.9079\n",
            "Epoch 12/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5131 - acc: 0.8723 - val_loss: 0.3335 - val_acc: 0.9583\n",
            "Epoch 13/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5054 - acc: 0.8734 - val_loss: 0.2958 - val_acc: 0.9580\n",
            "Epoch 14/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5164 - acc: 0.8706 - val_loss: 0.5027 - val_acc: 0.9052\n",
            "Epoch 15/40\n",
            "937/937 [==============================] - 14s 15ms/step - loss: 0.5155 - acc: 0.8704 - val_loss: 0.2191 - val_acc: 0.9795\n",
            "Epoch 16/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5108 - acc: 0.8727 - val_loss: 0.2722 - val_acc: 0.9669\n",
            "Epoch 17/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5087 - acc: 0.8725 - val_loss: 0.2504 - val_acc: 0.9732\n",
            "Epoch 18/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5120 - acc: 0.8710 - val_loss: 0.4993 - val_acc: 0.9011\n",
            "Epoch 19/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5072 - acc: 0.8731 - val_loss: 0.2887 - val_acc: 0.9646\n",
            "Epoch 20/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5137 - acc: 0.8711 - val_loss: 0.3862 - val_acc: 0.9302\n",
            "Epoch 21/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5118 - acc: 0.8716 - val_loss: 0.2340 - val_acc: 0.9739\n",
            "Epoch 22/40\n",
            "937/937 [==============================] - 14s 15ms/step - loss: 0.5172 - acc: 0.8700 - val_loss: 0.2793 - val_acc: 0.9626\n",
            "Epoch 23/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5115 - acc: 0.8723 - val_loss: 0.2428 - val_acc: 0.9728\n",
            "Epoch 24/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5092 - acc: 0.8712 - val_loss: 0.2761 - val_acc: 0.9642\n",
            "Epoch 25/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5085 - acc: 0.8718 - val_loss: 0.2788 - val_acc: 0.9676\n",
            "Epoch 26/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5125 - acc: 0.8706 - val_loss: 0.3195 - val_acc: 0.9467\n",
            "Epoch 27/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5069 - acc: 0.8729 - val_loss: 0.2197 - val_acc: 0.9829\n",
            "Epoch 28/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5130 - acc: 0.8711 - val_loss: 0.2505 - val_acc: 0.9681\n",
            "Epoch 29/40\n",
            "937/937 [==============================] - 13s 14ms/step - loss: 0.5158 - acc: 0.8704 - val_loss: 0.2418 - val_acc: 0.9723\n",
            "Epoch 30/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5109 - acc: 0.8708 - val_loss: 0.2336 - val_acc: 0.9759\n",
            "Epoch 31/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5065 - acc: 0.8724 - val_loss: 0.2285 - val_acc: 0.9748\n",
            "Epoch 32/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5094 - acc: 0.8709 - val_loss: 0.2386 - val_acc: 0.9717\n",
            "Epoch 33/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5066 - acc: 0.8721 - val_loss: 0.2424 - val_acc: 0.9673\n",
            "Epoch 34/40\n",
            "937/937 [==============================] - 13s 13ms/step - loss: 0.5145 - acc: 0.8714 - val_loss: 0.2113 - val_acc: 0.9788\n",
            "Epoch 35/40\n",
            "937/937 [==============================] - 14s 14ms/step - loss: 0.5080 - acc: 0.8717 - val_loss: 0.2259 - val_acc: 0.9775\n",
            "Epoch 36/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5030 - acc: 0.8731 - val_loss: 0.2604 - val_acc: 0.9702\n",
            "Epoch 37/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5103 - acc: 0.8717 - val_loss: 0.3225 - val_acc: 0.9501\n",
            "Epoch 38/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5084 - acc: 0.8716 - val_loss: 0.3093 - val_acc: 0.9519\n",
            "Epoch 39/40\n",
            "937/937 [==============================] - 14s 15ms/step - loss: 0.5184 - acc: 0.8697 - val_loss: 0.2940 - val_acc: 0.9612\n",
            "Epoch 40/40\n",
            "937/937 [==============================] - 12s 13ms/step - loss: 0.5097 - acc: 0.8713 - val_loss: 0.2244 - val_acc: 0.9732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f04308514a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "b3a0722d-3c46-4828-f49c-e6e6b189b535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.21949351046085358, 0.9746]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b19I17-NVSDR",
        "colab_type": "code",
        "outputId": "a02bf235-52e2-4877-8f9e-abc8c4a5f2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "def randIm():\n",
        "    i = np.random.choice(np.arange(0, len(Y_test)), size = (1,))\n",
        "    pred = model.predict(X_test[i])\n",
        "    image = (X_test[i].reshape(28, 28))\n",
        "    # show the prediction\n",
        "    print (\"Actual digit is\", Y_test[i], \"predicted\", pred[0])\n",
        "    imgplot = plt.imshow(image)\n",
        "    imgplot.set_cmap('gray')   \n",
        "\n",
        "randIm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual digit is [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] predicted [3.1973154e-04 3.1973154e-04 3.1973154e-04 3.1973154e-04 9.9712235e-01\n",
            " 3.1973154e-04 3.1973154e-04 3.1973154e-04 3.1973154e-04 3.1973154e-04]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/knVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}